{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import torch.autograd as ag\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import nltk\n",
    "import numpy as np\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-3.2.0-cp27-cp27mu-manylinux1_x86_64.whl (15.9MB)\n",
      "\u001b[K    100% |################################| 15.9MB 28kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting smart-open>=1.2.1 (from gensim)\n",
      "  Downloading smart_open-1.5.6.tar.gz\n",
      "Requirement already satisfied: six>=1.5.0 in /home/nbuser/anaconda2_501/lib/python2.7/site-packages (from gensim)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /home/nbuser/anaconda2_501/lib/python2.7/site-packages (from gensim)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /home/nbuser/anaconda2_501/lib/python2.7/site-packages (from gensim)\n",
      "Requirement already satisfied: boto>=2.32 in /home/nbuser/anaconda2_501/lib/python2.7/site-packages (from smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: bz2file in /home/nbuser/anaconda2_501/lib/python2.7/site-packages (from smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: requests in /home/nbuser/anaconda2_501/lib/python2.7/site-packages (from smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: boto3 in /home/nbuser/anaconda2_501/lib/python2.7/site-packages (from smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/nbuser/anaconda2_501/lib/python2.7/site-packages (from requests->smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /home/nbuser/anaconda2_501/lib/python2.7/site-packages (from requests->smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /home/nbuser/anaconda2_501/lib/python2.7/site-packages (from requests->smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/nbuser/anaconda2_501/lib/python2.7/site-packages (from requests->smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/nbuser/anaconda2_501/lib/python2.7/site-packages (from boto3->smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: botocore<1.9.0,>=1.8.0 in /home/nbuser/anaconda2_501/lib/python2.7/site-packages (from boto3->smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /home/nbuser/anaconda2_501/lib/python2.7/site-packages (from boto3->smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/nbuser/anaconda2_501/lib/python2.7/site-packages (from botocore<1.9.0,>=1.8.0->boto3->smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: docutils>=0.10 in /home/nbuser/anaconda2_501/lib/python2.7/site-packages (from botocore<1.9.0,>=1.8.0->boto3->smart-open>=1.2.1->gensim)\n",
      "Requirement already satisfied: futures<4.0.0,>=2.2.0; python_version == \"2.6\" or python_version == \"2.7\" in /home/nbuser/anaconda2_501/lib/python2.7/site-packages (from s3transfer<0.2.0,>=0.1.10->boto3->smart-open>=1.2.1->gensim)\n",
      "Building wheels for collected packages: smart-open\n",
      "  Running setup.py bdist_wheel for smart-open ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/nbuser/.cache/pip/wheels/36/48/35/97efc2bd1b233627131c9a936c9de23681846db707b907d353\n",
      "Successfully built smart-open\n",
      "Installing collected packages: smart-open, gensim\n",
      "Successfully installed gensim-3.2.0 smart-open-1.5.6\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_B_task_dataset(file_path):\n",
    "    assert isinstance(file_path, str)  # Type check\n",
    "    messages, polarities = [], []\n",
    "    with open(file_path) as dataset_file:\n",
    "        for instance in csv.reader(dataset_file, delimiter='\\t'):\n",
    "            context, message, polarity = instance[-3], instance[-1], instance[-2]\n",
    "            messages.append(message)\n",
    "            if polarity == 'negative':\n",
    "                polarities.append(0)\n",
    "            elif polarity == 'positive':\n",
    "                polarities.append(2)\n",
    "            else:\n",
    "                polarities.append(1)\n",
    "    return messages, polarities\n",
    "\n",
    "\n",
    "def clean_digit(token):\n",
    "    if re.search(r'.*\\d.*', token): #whatever_digit_whatever\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def clean_url(token):\n",
    "    if re.search(r'\\w+\\.\\w+', token): #word.word\n",
    "        return False\n",
    "    if not (token.startswith(\"http\") or token.startswith(\"www\")):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def clean_punc(token):\n",
    "    punc = [\".\", \";\", \"!\", \":\", \"(\", \")\", \"[\", \"]\", \"?\", \",\", \"&\", \"-\", \"$\", \"~\", \"#\", \"{\", \"}\", \"/\", \"\\\\\", '\\'', '\\\"', '<', '>', '`', \"+\", \"|\", \"^\",\"@\",\"%\",\"=\",\"*\"]\n",
    "    if token in punc:\n",
    "        return False\n",
    "    if re.search(r'-+>', token): #----->\n",
    "        return False\n",
    "    if re.search(r'<-+', token): # <-----\n",
    "        return False\n",
    "    if re.search(r'\\.+', token): #........\n",
    "        return False\n",
    "    if re.search(r'(\\.\\s)+\\.', token): #. . . .\n",
    "        return False\n",
    "    if re.search(r':+', token): #:::::\n",
    "        return False\n",
    "    if re.search(r'\\</?\\w>', token): #Balises\n",
    "        return False\n",
    "    if re.match(r'_+', token): #____\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def clean_tag(token):\n",
    "    if re.search(r'@\\w+', token): #@person , Emails\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def clean_hashtag(token):\n",
    "    if token.startswith(\"#\"):\n",
    "        hashtag = token[1:]\n",
    "        #print(\"hashtag = \"+ hashtag)\n",
    "        hashtag_parts = []\n",
    "        part = \"\"\n",
    "        for c in hashtag:\n",
    "            if(c.islower()):\n",
    "                part += c\n",
    "            else: #upper\n",
    "                if(part != \"\"):\n",
    "                    hashtag_parts.append(part)\n",
    "                    part = \"\"+c\n",
    "                else:\n",
    "                    part = \"\"+c\n",
    "        if (part != \"\"):\n",
    "            hashtag_parts.append(part)\n",
    "        #print(\"hashtag parts = \"+ str(hashtag_parts))\n",
    "\n",
    "    return token\n",
    "\n",
    "\n",
    "def process_messages(raw_messages):  # For raw messages, each message is str\n",
    "    from nltk.corpus import stopwords\n",
    "    try:\n",
    "        stop_words = set(stopwords.words())\n",
    "    except LookupError:\n",
    "        nltk.download('stopwords')\n",
    "        stop_words = set(stopwords.words())\n",
    "    assert isinstance(raw_messages, list) and all(isinstance(msg, str) for msg in raw_messages)  # Type check\n",
    "    tokenizer = nltk.tokenize.TweetTokenizer(preserve_case=True, strip_handles=True, reduce_len=True)\n",
    "    tokened_messages = [tokenizer.tokenize(msg) for msg in raw_messages]\n",
    "    clean_tokens = [[token for token in tokens if token not in stop_words and clean_url(token) and clean_digit(token) and clean_punc(token) and clean_tag(token)] for tokens in tokened_messages]\n",
    "    no_hashtag_tokens = [[clean_hashtag(token) for token in tokens] for tokens in clean_tokens]\n",
    "    return no_hashtag_tokens\n",
    "\n",
    "\n",
    "def generate_vocabulary(processed_messages):  # For processed messages, each message is list of tokens\n",
    "    assert isinstance(processed_messages, list) and all(isinstance(msg, list) for msg in processed_messages)  # Type check\n",
    "    vocabulary = set()\n",
    "    for message in processed_messages:\n",
    "        vocabulary.update(message)\n",
    "    return vocabulary\n",
    "\n",
    "\n",
    "def get_indices(vocabulary):\n",
    "    assert isinstance(vocabulary, set)\n",
    "    words_indices = {}\n",
    "    index = 0\n",
    "    for word in vocabulary:\n",
    "        words_indices[word] = index\n",
    "        index += 1\n",
    "    return words_indices\n",
    "\n",
    "\n",
    "def transform_to_indices(processed_messages, words_indices):\n",
    "    assert isinstance(processed_messages, list) and all(isinstance(msg, list) for msg in processed_messages)\n",
    "    assert isinstance(words_indices, dict) and all(isinstance(v, int) for v in words_indices.values())  # Type check\n",
    "    return [[words_indices[w] for w in msg] for msg in processed_messages]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_file_train = 'B_train.dist'\n",
    "messages, polarities = load_B_task_dataset(data_file_train)\n",
    "\n",
    "data_file_dev = 'B_dev.dist'\n",
    "messages_dev, polarities_dev = load_B_task_dataset(data_file_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary Statistics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5916\n",
      "876\n",
      "counter train : Counter({1: 2921, 2: 2179, 0: 816})\n",
      "counter dev : Counter({1: 394, 2: 324, 0: 158})\n"
     ]
    }
   ],
   "source": [
    "print(len(messages))\n",
    "print(len(messages_dev))\n",
    "\n",
    "#class distribution\n",
    "import collections\n",
    "\n",
    "counter_train=collections.Counter(polarities)\n",
    "print(\"counter train : %s\" %counter_train)\n",
    "counter_dev=collections.Counter(polarities_dev)\n",
    "print(\"counter dev : %s\" %counter_dev)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Gas by my house hit $3.39!!!! I'm going to Chapel Hill on Sat. :)\", \"Iranian general says Israel's Iron Dome can't deal with their missiles (keep talking like that and we may end up finding out)\", 'with J Davlar 11th. Main rivals are team Poland. Hopefully we an make it a successful end to a tough week of training tomorrow.', \"Talking about ACT's && SAT's, deciding where I want to go to college, applying to colleges and everything about college stresses me out.\", \"They may have a SuperBowl in Dallas, but Dallas ain't winning a SuperBowl. Not with that quarterback and owner. @S4NYC @RasmussenPoll\"]\n"
     ]
    }
   ],
   "source": [
    "print(messages[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Gas',\n",
       " u'by',\n",
       " u'my',\n",
       " u'house',\n",
       " u'hit',\n",
       " u'$',\n",
       " u'3.39',\n",
       " u'!',\n",
       " u'!',\n",
       " u'!',\n",
       " u\"I'm\",\n",
       " u'going',\n",
       " u'to',\n",
       " u'Chapel',\n",
       " u'Hill',\n",
       " u'on',\n",
       " u'Sat',\n",
       " u'.',\n",
       " u':)']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = nltk.tokenize.TweetTokenizer(preserve_case=True, strip_handles=True, reduce_len=True)\n",
    "tokenizer.tokenize(messages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n",
      "38\n",
      "40\n",
      "4\n",
      "6\n",
      "5\n",
      "23.0\n",
      "23.0\n",
      "23.0\n"
     ]
    }
   ],
   "source": [
    "pos_indices = [i for i, j in enumerate(polarities) if j == 2]\n",
    "neg_indices = [i for i, j in enumerate(polarities) if j == 0]\n",
    "neut_indices = [i for i, j in enumerate(polarities) if j == 1]\n",
    "\n",
    "positives = [tokenizer.tokenize(messages[i]) for i in pos_indices]\n",
    "negatives = [tokenizer.tokenize(messages[i]) for i in neg_indices]\n",
    "neutrals = [tokenizer.tokenize(messages[i]) for i in neut_indices]\n",
    "\n",
    "print(max([len(msg) for msg in positives]))\n",
    "print(max([len(msg) for msg in negatives]))\n",
    "print(max([len(msg) for msg in neutrals]))\n",
    "\n",
    "print(min([len(msg) for msg in positives]))\n",
    "print(min([len(msg) for msg in negatives]))\n",
    "print(min([len(msg) for msg in neutrals]))\n",
    "\n",
    "print(np.ceil(np.mean([len(msg) for msg in positives])))\n",
    "print(np.ceil(np.mean([len(msg) for msg in negatives])))\n",
    "print(np.ceil(np.mean([len(msg) for msg in neutrals])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "34\n",
      "38\n",
      "7\n",
      "8\n",
      "6\n",
      "23.0\n",
      "23.0\n",
      "22.0\n"
     ]
    }
   ],
   "source": [
    "pos_indices = [i for i, j in enumerate(polarities_dev) if j == 2]\n",
    "neg_indices = [i for i, j in enumerate(polarities_dev) if j == 0]\n",
    "neut_indices = [i for i, j in enumerate(polarities_dev) if j == 1]\n",
    "\n",
    "positives = [tokenizer.tokenize(messages_dev[i]) for i in pos_indices]\n",
    "negatives = [tokenizer.tokenize(messages_dev[i]) for i in neg_indices]\n",
    "neutrals = [tokenizer.tokenize(messages_dev[i]) for i in neut_indices]\n",
    "\n",
    "print(max([len(msg) for msg in positives]))\n",
    "print(max([len(msg) for msg in negatives]))\n",
    "print(max([len(msg) for msg in neutrals]))\n",
    "\n",
    "print(min([len(msg) for msg in positives]))\n",
    "print(min([len(msg) for msg in negatives]))\n",
    "print(min([len(msg) for msg in neutrals]))\n",
    "\n",
    "print(np.ceil(np.mean([len(msg) for msg in positives])))\n",
    "print(np.ceil(np.mean([len(msg) for msg in negatives])))\n",
    "print(np.ceil(np.mean([len(msg) for msg in neutrals])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_messages = process_messages(messages)\n",
    "p_messages_dev = process_messages(messages_dev)\n",
    "vocab = generate_vocabulary(p_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17284"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_freq = {}\n",
    "for w in vocab:\n",
    "    word_freq[w] = 0\n",
    "for msg in p_messages:\n",
    "    for word in msg:\n",
    "        word_freq[word]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcd229e0ed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns \n",
    "import operator\n",
    "import math\n",
    "%matplotlib inline\n",
    " \n",
    "y = sorted(list(word_freq.values()))\n",
    "x = list(range(len(y)))\n",
    "\n",
    "\n",
    "low = min(y)\n",
    "high = max(y)\n",
    "plt.ylim([0, 200])\n",
    "plt.bar(x, y)\n",
    "plt.title('word frequency in tweets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "20\n",
      "22\n",
      "3\n",
      "3\n",
      "3\n",
      "12.0\n",
      "13.0\n",
      "12.0\n"
     ]
    }
   ],
   "source": [
    "pos_indices = [i for i, j in enumerate(polarities) if j == 2]\n",
    "neg_indices = [i for i, j in enumerate(polarities) if j == 0]\n",
    "neut_indices = [i for i, j in enumerate(polarities) if j == 1]\n",
    "\n",
    "positives = [p_messages[i] for i in pos_indices]\n",
    "negatives = [p_messages[i] for i in neg_indices]\n",
    "neutrals = [p_messages[i] for i in neut_indices]\n",
    "\n",
    "print(max([len(msg) for msg in positives]))\n",
    "print(max([len(msg) for msg in negatives]))\n",
    "print(max([len(msg) for msg in neutrals]))\n",
    "\n",
    "print(min([len(msg) for msg in positives]))\n",
    "print(min([len(msg) for msg in negatives]))\n",
    "print(min([len(msg) for msg in neutrals]))\n",
    "\n",
    "print(np.ceil(np.mean([len(msg) for msg in positives])))\n",
    "print(np.ceil(np.mean([len(msg) for msg in negatives])))\n",
    "print(np.ceil(np.mean([len(msg) for msg in neutrals])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_vocabulary_embeddings(vocabulary, p_messages):\n",
    "    \n",
    "    embedding_size = 100\n",
    "    model = gensim.models.Word2Vec(p_messages, min_count = 1, size = embedding_size)\n",
    "    print (type(model))\n",
    "    i=0\n",
    "    vocabulary_embeddings = []\n",
    "    embeddings_indices = {}\n",
    "    for word in vocabulary:\n",
    "        embedding = model[word]\n",
    "        \n",
    "        vocabulary_embeddings.append(embedding)\n",
    "        embeddings_indices[word] = i\n",
    "        i += 1\n",
    "    vocabulary_embeddings = np.array(vocabulary_embeddings)\n",
    "    return vocabulary_embeddings, embeddings_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'gensim.models.word2vec.Word2Vec'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nbuser/anaconda2_501/lib/python2.7/site-packages/ipykernel/__main__.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "vocabulary_embeddings,  embeddings_indices = create_vocabulary_embeddings(vocab, p_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n",
      "[  5.92030643e-04  -3.42225889e-04  -5.03302878e-03  -3.94049473e-03\n",
      "  -1.24863276e-04  -4.21266258e-03   2.09194928e-04  -1.21670484e-03\n",
      "  -2.52216851e-04  -3.49092181e-03   5.47816744e-03   4.21802630e-04\n",
      "  -1.96429295e-03   1.38742290e-03   3.81470798e-03  -3.49098467e-03\n",
      "   2.85565085e-03   1.69433898e-03   5.94719406e-03  -3.88491875e-03\n",
      "   7.36129296e-04   3.86118609e-03  -3.84490751e-03  -3.98706133e-03\n",
      "  -3.10851564e-03   2.63054064e-03  -2.26785964e-03  -7.17601448e-04\n",
      "  -4.68426530e-04   2.31674267e-03  -2.76723877e-03   4.94276313e-03\n",
      "   3.45109525e-04  -8.23360242e-05   3.69277713e-03   3.12332413e-03\n",
      "  -3.55879311e-03  -1.30166567e-03  -1.05998683e-04  -4.33193706e-03\n",
      "  -2.16496192e-04  -5.66866994e-03  -3.84996389e-03  -7.34965608e-04\n",
      "  -3.04086017e-03  -4.62904852e-03   4.52505751e-03  -2.75416882e-03\n",
      "   6.13566395e-03   3.24629829e-04   4.80645627e-04  -2.28602905e-03\n",
      "  -9.38326353e-04   1.47350482e-03   1.27263868e-03  -8.89866264e-04\n",
      "   2.11313623e-03   5.67394949e-04  -3.82876286e-04  -4.99654282e-03\n",
      "  -4.81612794e-03   1.39083117e-04  -3.05573596e-03   3.88868805e-03\n",
      "  -3.92674468e-03  -7.61494855e-04  -2.80907773e-03   3.36929155e-03\n",
      "  -1.61018257e-03   2.38320720e-03  -2.33753235e-03   2.39345548e-03\n",
      "   2.37959716e-03   2.60196021e-03  -4.24571335e-03   2.41838908e-03\n",
      "  -4.27921116e-03  -2.86772312e-03   4.32842551e-03   6.05559861e-03\n",
      "  -2.67149851e-04  -1.11784693e-03  -1.66288635e-03   7.49514787e-04\n",
      "  -1.50927517e-04  -1.98704051e-03   2.89856130e-03  -1.64287037e-03\n",
      "  -2.89407815e-03   7.44901772e-04  -4.18480160e-03   2.11673370e-03\n",
      "   1.17093872e-03  -5.59544424e-03  -4.94398922e-03  -3.93114612e-03\n",
      "  -1.74481969e-03  -5.92051074e-04  -2.38646497e-03   8.95746169e-04]\n"
     ]
    }
   ],
   "source": [
    "print(vocabulary_embeddings[0].shape)\n",
    "print(vocabulary_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.zeros((len(p_messages), len(vocabulary_embeddings[0])))\n",
    "messages_indices = transform_to_indices(p_messages, embeddings_indices)\n",
    "for i,msg in enumerate(messages_indices):\n",
    "    sum_emb = np.zeros(len(vocabulary_embeddings[0]))\n",
    "    for word in msg:\n",
    "        sum_emb += vocabulary_embeddings[word]\n",
    "    X_train[i] = sum_emb\n",
    "\n",
    "y_train = np.array(polarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5916, 100)\n",
      "(5916,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.512647554806\n",
      "0.540540540541\n",
      "0.513513513514\n",
      "0.521959459459\n",
      "0.5\n",
      "0.530405405405\n",
      "0.521150592217\n",
      "0.495769881557\n",
      "0.48730964467\n",
      "0.493220338983\n",
      "mean accuracy: 0.51\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "clf = MLPClassifier(hidden_layer_sizes=(100,))\n",
    "mean_acc = []\n",
    "for train_indices, test_indices in skf.split(X_train, y_train):\n",
    "    clf.fit(X_train[train_indices], y_train[train_indices])\n",
    "    accuracy = clf.score(X_train[test_indices], y_train[test_indices])\n",
    "    mean_acc.append(accuracy)\n",
    "    print(accuracy)\n",
    "print('mean accuracy: %.2f'%np.mean(mean_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
